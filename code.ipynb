{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析项目 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目的目标是基于用户提供的评论，通过算法自动去判断其评论是正面的还是负面的情感。比如给定一个用户的评论：\n",
    "- 评论1： “我特别喜欢这个电器，我已经用了3个月，一点问题都没有！”\n",
    "- 评论2： “我从这家淘宝店卖的东西不到一周就开始坏掉了，强烈建议不要买，真实浪费钱”\n",
    "\n",
    "对于这两个评论，第一个明显是正面的，第二个是负面的。 我们希望搭建一个AI算法能够自动帮我们识别出评论是正面还是负面。\n",
    "\n",
    "情感分析的应用场景非常丰富，也是NLP技术在不同场景中落地的典范。比如对于一个证券领域，作为股民，其实比较关注舆论的变化，这个时候如果能有一个AI算法自动给网络上的舆论做正负面判断，然后把所有相关的结论再整合，这样我们可以根据这些大众的舆论，辅助做买卖的决策。 另外，在电商领域评论无处不在，而且评论已经成为影响用户购买决策的非常重要的因素，所以如果AI系统能够自动分析其情感，则后续可以做很多有意思的应用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情感分析是文本处理领域经典的问题。整个系统一般会包括几个模块：\n",
    "- 数据的抓取： 通过爬虫的技术去网络抓取相关文本数据\n",
    "- 数据的清洗/预处理：在本文中一般需要去掉无用的信息，比如各种标签（HTML标签），标点符号，停用词等等\n",
    "- 把文本信息转换成向量： 这也成为特征工程，文本本身是不能作为模型的输入，只有数字（比如向量）才能成为模型的输入。所以进入模型之前，任何的信号都需要转换成模型可识别的数字信号（数字，向量，矩阵，张量...)\n",
    "- 选择合适的模型以及合适的评估方法。 对于情感分析来说，这是二分类问题（或者三分类：正面，负面，中性），所以需要采用分类算法比如逻辑回归，朴素贝叶斯，神经网络，SVM等等。另外，我们需要选择合适的评估方法，比如对于一个应用，我们是关注准确率呢，还是关注召回率呢？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次项目中，我们已经给定了训练数据和测试数据，它们分别是 train.positive.txt, train.negative.txt， test_combined.txt. 请注意训练数据和测试数据的格式不一样，详情请见文件内容。 整个项目你需要完成以下步骤：\n",
    "\n",
    "数据的读取以及清洗： 从给定的.txt中读取内容，并做一些数据清洗，这里需要做几个工作： （1） 文本的读取，需要把字符串内容读进来。 （2）去掉无用的字符比如标点符号，多余的空格，换行符等 （3） 分词\n",
    "把文本转换成TF-IDF向量： 这部分直接可以利用sklearn提供的TfidfVectorizer类来做。\n",
    "利用逻辑回归模型来做分类，并通过交叉验证选择最合适的超参数\n",
    "利用支持向量机做分类，并通过交叉验证选择神经网络的合适的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Reading: 文本读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_train_file(file_path):\n",
    "    comments = []  # 用来存储评论\n",
    "    labels = []   # 存储标签\n",
    "    with open(file_path) as file:\n",
    "        # TODO 提取每一个评论，然后利用process_line函数来做处理，并添加到comments。\n",
    "        text = file.read().replace(' ','').replace('\\n','')\n",
    "        reg = '<reviewid=\"\\d{1,4}\">(.*?)</review>'\n",
    "        result = re.findall(reg,text)\n",
    "        for r in result:\n",
    "            comments.append(r)\n",
    "            if file_path == 'data/train.positive.txt':\n",
    "                labels.append('1')\n",
    "            else:\n",
    "                labels.append('0')\n",
    "    return comments, labels\n",
    "\n",
    "def read_test_file(file_path):\n",
    "    comments = []  # 用来存储评论\n",
    "    labels = []   # 存储标签\n",
    "    with open(file_path) as file:\n",
    "        # TODO 提取每一个评论，然后利用process_line函数来做处理，并添加到comments。\n",
    "        text = file.read().replace(' ','').replace('\\n','')\n",
    "        reg = '<reviewid=\"\\d{1,4}\".*?</review>'\n",
    "        result = re.findall(reg,text)\n",
    "        for r in result:\n",
    "            label_reg = '<reviewid=\"\\d{1,4}\"label=\"(\\d)\">'\n",
    "            com_reg = '>(.*?)</review>'\n",
    "            label = re.findall(label_reg,r)[0]\n",
    "            comment = re.findall(com_reg,r)[0]\n",
    "            labels.append(label)\n",
    "            comments.append(comment)\n",
    "    return comments, labels\n",
    "    \n",
    "        \n",
    "def process_file():\n",
    "    \"\"\"\n",
    "    读取训练数据和测试数据，并对它们做一些预处理\n",
    "    \"\"\"    \n",
    "    train_pos_file = \"data/train.positive.txt\"\n",
    "    train_neg_file = \"data/train.negative.txt\"\n",
    "    test_comb_file = \"data/test.combined.txt\"\n",
    "    \n",
    "    # TODO: 读取文件部分，把具体的内容写入到变量里面\n",
    "    train_pos_comments, train_pos_labels = read_train_file(train_pos_file)\n",
    "    train_neg_comments, train_neg_labels = read_train_file(train_neg_file)\n",
    "    test_comments, test_labels = read_test_file(test_comb_file)\n",
    "    return train_pos_comments, train_pos_labels,train_neg_comments, train_neg_labels,test_comments, test_labels\n",
    "    \n",
    "train_pos_comments, train_pos_labels,train_neg_comments, train_neg_labels,test_comments, test_labels = process_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorary Analysis: 做一些简单的可视化分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8065 2500\n"
     ]
    }
   ],
   "source": [
    "train_comments = train_pos_comments + train_neg_comments\n",
    "train_labels = train_pos_labels + train_neg_labels\n",
    "\n",
    "# 训练数据和测试数据大小\n",
    "print (len(train_comments), len(test_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/1y/y3wkm_bd157fxlr0npb5zv9r0000gn/T/jieba.cache\n",
      "Loading model cost 1.777 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1145a96d8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD3CAYAAADxJYRbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146fdf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jieba\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# TODO: 对于训练数据中的正负样本，分别画出一个histogram， histogram的x抽是每一个样本中字符串的长度，y轴是拥有这个长度的样本的百分比。\n",
    "#       并说出样本长度是否对情感有相关性 (需要先用到结巴分词)\n",
    "#       参考：https://en.wikipedia.org/wiki/Histogram\n",
    "def count_sentence(sentences):\n",
    "    len_list = []\n",
    "    for s in sentences:\n",
    "        sentence = []\n",
    "        for i in jieba.cut(s):\n",
    "            sentence.append(i)\n",
    "        len_list.append(len(sentence))\n",
    "    return len_list\n",
    "\n",
    "\n",
    "sns.distplot(count_sentence(train_pos_comments))   # train_pos_comments样本中各长度样本所占百分比\n",
    "sns.distplot(count_sentence(train_neg_comments))   # train_neg_comments样本中各长度样本所占百分比\n",
    "\n",
    "# 右下图中可以观察到，正负样本的长度所占百分比的趋势基本接近，说明样本长度与情感没有相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '的', '。', '了', '是', '！', '很', ',', '我', '也', '在', '有', '~', '都', '好', '.', '不错', '就', '买', '喜欢']\n",
      "['，', '的', '。', '了', '！', '是', '我', ',', '不', '买', '就', '也', '都', '很', '有', '在', '？', '没有', '!', '.']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# TODO： 分别列出训练数据中正负样本里的top 20单词（可以做适当的stop words removal）。 \n",
    "def get_top20_words(comments):\n",
    "    word_library = []   # 储存所有词\n",
    "    for comment in comments:\n",
    "        for i in jieba.cut(comment):\n",
    "            word_library.append(i)\n",
    "    word_dic = collections.Counter(word_library).most_common(20)\n",
    "    top20_list = [i[0] for i in word_dic]\n",
    "    return top20_list\n",
    "\n",
    "print(get_top20_words(train_pos_comments))\n",
    "print(get_top20_words(train_neg_comments))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根据正负样本里的top 20单词，手动生成停用词库\n",
    "stop_words = ['的','了','是','很','我','也','在','买','有','都','就']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning: 文本处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "# TODO：对于train_comments, test_comments进行字符串的处理，几个考虑的点：\n",
    "#   1. 停用词过滤\n",
    "#   2. 去掉特殊符号\n",
    "#   3. 去掉数字（比如价格..)\n",
    "#   4. ...\n",
    "#   需要注意的点是，由于评论数据本身很短，如果去掉的太多，很可能字符串长度变成0\n",
    "#   预处理部部分，可以自行选择合适的方案，只要注释就可以。\n",
    "def text_preprocessing(comments):\n",
    "    comments_new = []\n",
    "    for comment in comments:\n",
    "        sentence = ''\n",
    "        for word in list(jieba.cut(comment)):\n",
    "            # 去除停用词、标点符号、数字\n",
    "            if word not in set(stop_words) and word.isalnum() and not word.isdigit():\n",
    "                sentence += word + ' '\n",
    "        comments_new.append(sentence)\n",
    "    return comments_new\n",
    "    \n",
    "train_comments_new = text_preprocessing(train_comments)\n",
    "test_comments_new = text_preprocessing(test_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction : 从文本中提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8065, 43903) (2500, 43903) (8065,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "# TODO: 利用tf-idf从文本中提取特征,写到数组里面. \n",
    "#       参考：https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "tfid_vec = TfidfVectorizer()\n",
    "X_train = tfid_vec.fit_transform(train_comments)\n",
    "y_train = np.array(train_labels)\n",
    "X_test = tfid_vec.transform(test_comments)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling: 训练模型以及选择合适的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000.0}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.17      0.28      1250\n",
      "          1       0.53      0.94      0.68      1250\n",
      "\n",
      "avg / total       0.64      0.56      0.48      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# TODO： 利用逻辑回归来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       逻辑回归的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#       对于逻辑回归，经常调整的超参数为： C\n",
    " \n",
    "parameters = { 'C':np.logspace(-3,3,7)}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'kernel': 'linear'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.17      0.28      1250\n",
      "          1       0.53      0.95      0.68      1250\n",
      "\n",
      "avg / total       0.65      0.56      0.48      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# TODO： 利用SVM来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':np.logspace(-3,3,7)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于超参数的调整，我们经常使用gridsearch，这也是工业界最常用的方法，但它的缺点是需要大量的计算，所以近年来这方面的研究也成为了重点。 其中一个比较经典的成果为Bayesian Optimization（利用贝叶斯的思路去寻找最好的超参数）。Ryan P. Adams主导的Bayesian Optimization利用高斯过程作为后验概率（posteior distribution）来寻找最优解。 https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf 在下面的练习中，我们尝试使用Bayesian Optimization工具来去寻找最优的超参数。参考工具：https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 仍然使用SVM模型，但在这里使用Bayesian Optimization来寻找最好的超参数。 \n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用Bayesian Optimization https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "#       参考Bayesian Optimization开源工具： https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_cv(C, gamma):\n",
    "    svm = SVC(C=10 ** C, gamma=10 ** gamma,random_state=1)\n",
    "    val = cross_val_score(svm,X_train, y_train, cv=5).mean()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbounds = {'C':(0,1),'gamma':(2,20)}\n",
    "svm_bo = BayesianOptimization(svm_cv,pbounds=pbounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5383  \u001b[0m | \u001b[0m 17.17   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.03277 \u001b[0m | \u001b[0m 11.02   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.391   \u001b[0m | \u001b[0m 18.42   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.6569  \u001b[0m | \u001b[0m 7.471   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 12.38   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.01734 \u001b[0m | \u001b[0m 2.001   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2771  \u001b[0m | \u001b[0m 2.024   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5181  \u001b[0m | \u001b[0m 19.96   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5492  \u001b[0m | \u001b[0m 2.058   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.7518  \u001b[0m | \u001b[0m 19.91   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.05667 \u001b[0m | \u001b[0m 2.061   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.313   \u001b[0m | \u001b[0m 19.9    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.07876 \u001b[0m | \u001b[0m 2.006   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2191  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.6871  \u001b[0m | \u001b[0m 2.068   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2401  \u001b[0m | \u001b[0m 19.93   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.4216  \u001b[0m | \u001b[0m 2.095   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.3158  \u001b[0m | \u001b[0m 19.84   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.3842  \u001b[0m | \u001b[0m 2.057   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 19.91   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2597  \u001b[0m | \u001b[0m 2.063   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.1796  \u001b[0m | \u001b[0m 19.85   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.1496  \u001b[0m | \u001b[0m 2.061   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.6526  \u001b[0m | \u001b[0m 19.93   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.03424 \u001b[0m | \u001b[0m 2.001   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.6447  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.08439 \u001b[0m | \u001b[0m 2.045   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.94    \u001b[0m | \u001b[0m 19.96   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.818   \u001b[0m | \u001b[0m 2.086   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.4185  \u001b[0m | \u001b[0m 19.94   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "svm_bo.maximize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
